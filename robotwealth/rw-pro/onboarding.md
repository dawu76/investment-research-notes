### RW Pro onboarding notes

---

Highlights
- RW Pro API key: use API to pull weights into spreadsheet or some other application
- Research pods to house clean data and libraries for cleaning and analyzing data: use Google Colab notebooks to share code snippets of common code patterns / queries
- What's in the "Lab"? Edge database: maintained in Github, in the form of a spreadsheet or Kanban board, that collects info about the edges that RW has investigated before. On main page, click on Lab > Lab HQ > Course Content with videos
- Macro Pod: organized in similar way, with research findings and scripts, and links to any datasets; click on one of the research notebooks to see a walk-through of the findings and code; the notebook will pull code from APIs or from files in Github; occasionally, there may be changes in Colab or libraries that cause the code to break - if that happens, ask for help on Discord.
- There's a RwTools script with common utility snippets for downloading data via API, calculating certain quantities like EWMA, creating a histogram of returns, etc. This script is sourced at the top of many of these notebooks.
- In Colab, go to the settings cog and authorize it to have access to Github; also check the option to access private repos. Also go to Site settings and paste the URL of a Colab notebook into 'Custom snippet notebook URL' field, where the URL is copied from the Lab HQ course > 'Colab: Reproducible Research in the Lab' section. These same instructions are also in that course module. By doing so, you can get easy access to useful research code snippets from any notebook by clicking on '<>' in the LHS menu and filtering in the window. The research code snippets notebook itself is organized by research pod - e.g. equity factors (EF), macro, crypto, etc. When you run the snippets that access the RW data APIs, or run the `rwlab_data_auth()` line, you may get an authorization request in the browser asking you to authorize through your email (?)
- The Risk Premia on Steroids and Trading through Armageddon courses have particularly good lessons.

Brief walk-through of the 'Controlling for non-random stuff' notebook:
- We can very crudely look at a cross-sectional momentum effect, right? We have say if we've got 200 perpetual futures on Binance and we just go, Hey look, a crude measurement of momentum is just how much stuff has moved relative to everything else. And we can proxy momentum like that. We can go look over the last, let's pick a random number last 20 days, how much, what were the returns from every one of the perpetual futures in our universe? Then we can construct some kind of strategy that looks to go long, the stuff that had gone up the most and it looks to go short the stuff that's gone down the most.
- And if, you know, if this is a tradable idea, we would probably expect our crude way of measuring that to show some positive results. But we should also understand that there are other drivers to asset returns, right? We should, we should know for example, that some stuff is more liquid than others. Some stuff is more illiquid than others. Some stuff is more volatile, some stuff is less volatile, some stuff is bigger, some stuff is smaller. And all of these things, you know, volatility, liquidity, size, all those kind of things also have a slightly predictable result or impact on the returns of the assets. So we should be able to improve our simple cross-sectional momentum model by going, Hey look, can I take out the predictable stuff that is caused by differences in volatility, differences in size, differences in liquidity, and things like that. Yeah. So that's what this, this sort of piece of work is, is trying to, trying to teach, right? It's trying to go, Hey look, if we can control for all 52:06 of the non-random stuff that we know, which causes changes in price or returns and things, then that should allow the effect that we're trying to investigate to become more obvious, right? We might even sort of uncover things that we couldn't see before because it was masked by all this sort of other predictable stuff. You know, and we kind of saw this recent, this kind of thing recently when we were looking at VIX and we were looking at calendar effects and days of the week effects and things like that. Remember when we, when we kinda adjusted for all of the strange structure or issues in the VIX forward windows for different months, then being able to adjust for that then allowed us to see some mispricings that we weren't able to see before, right? We could see that, you know, historically December had traded too rich, right? Because the market was over estimating something that it shouldn't have done, right? 'cause it hadn't done that on average. It clearly hadn't done that adjustment correctly. Whereas if we adjust all the sources of non-randomness from our data, then other findings emerge. We kind of saw this recent, this kind of thing recently when we were looking at VIX
- This portion of the notebook looks into crypto 'perpetual swaps'. Here I'm getting the perpetual swap prices and the funding rates. This is my universe of of Binance swaps or Binance perpetual futures. I start in 2020 basically just having Bitcoin, Ethereum, and then we've gradually grown the potential size of the universe to the point that we've got about 200 different instruments that we could possibly trade. If we wanted to construct the biggest cross-sectional momentum basket that we could, we would be trading 200 perpetual swaps right now; we'd be long one, the stuff that went up the most, and we'd be short the the stuff that that went down the most. So the first thing we basically wanna is calculate some kind of momentum feature. Just do the simplest thing, right? You don't have to construct a perfect bit of analysis to start, just start with the dirtiest, quickest thing you can think of.
- So my quick and dirty step is to calculate the returns of each perpetual future in our universe over the last 20 days. Create the raw feature, which is the series of total returns -- the asset's price returns plus funding returns over the last 20 days. Then uses those returns to get a measure of cross-sectional momentum, which indicates how much each asset trended up relative to the other assets in the universe. We do this by scaling the returns to get a per-asset **Z-score**: substracting the mean return and dividing by the standard deviation of returns, both calculated over the trailing window period. This results in a score that's roughly within the [-3, 3] range. This normalized measure gives us a sense of how well each asset is doing in the recent period relative to its history. By comparing the Z-scores of assets at a given time, we get a sense of which assets are doing better or worse in the trailing period.
- Moving onto simple analysis: one of the simplest things is to look at the correlation of this momentum score with the perpetual future's returns in a subsequent period. So we have a dataset containing the momemtum score for each asset / date, and its return in a subsequent period, counting forward from the very next day. Question: are higher momentum scores associated with higher subsequent returns, and vice versa? The numbers in this table represent the correlation of a raw momentum feature with next day total returns. That's like 0.7%. The next number is the correlation of the momentum feature with price changes. And then this is correlation of it with 'funding accrual (returns)', which is 8% - you see that past momentum is slightly predictive of future funding, which kind of makes sense - if someone's buying something, it's probably going up, and it's more likely to have some kind of demand supply imbalance in the future. And it's more likely to be trading at a premium.
- The scatterplot of the momentum Z-score vs. log(total returns) would ideally have an upward sloping shape, but in reality, as with most trading-related data, it looks like a big blob, despite the small amount of predictive ability. Instead of plotting all of these data points, can we segment them into groups (e.g. by percentiles) and look for relationships between these coarser buckets?
- Another approach: use the Z-score as a long/short signal. What if we hold each asset in amounts proportional to their Z-score, e.g. short assets that have gone down or have gone up less than others, and go long assets that have performed better. This isn't a tradable strategy because it's super active, but it's a useful research tool because it gives us an idea of how stable the cross-sectional momentum effect is. From the cumulative returns chart for this strategy, we can see that this crude measure would've killed it from 2020 to 2022, but subsequently less so. This implementation is dumbed-down given the diversity of coins included in the universe here, as some of them are far less liquid and more volatile than others. An easy adjustment would be to narrow down the universe to the coins with larger market caps, excluding the really volatile, noisy stuff.
- The next barchart displays the 'information coefficient', which is the correlation of my signal with future returns. The red bar indicates how much our momentum signal explains future returns on the entire 200 asset universe, while the green bar indicates how much it explains future returns for the top 50 coins by market cap in our in our data set. We see a significantly stronger cross-sectional momentum effect on subsequent prices and total returns for just the top 50 assets. By the way, an interesting thing is that the momentum score is more strongly predictive of 'future funding returns' over the full universe of coins vs. just the top 50 (so futures funding returns are higher for the more volatile, small market cap coins). The line chart showing the time series of cumulative returns for the 'top 50 coins momentum strategy' shows more consistent performance over time than the same chart over the full asset universe.
- This exercise shows that it's good to start with crude analyses and simple measures, which let us test our hypotheses more quickly, and then iterate on those initial findings. A small improvement here could be to normalize the assets by volatility so that they have roughly the same volatility, even among the top 50 assets; doing so provides a small increase in momentum's explanatory power for price returns and a larger increase in explanatory power for funding rate returns among the top 50 assets. This analysis tells us that maybe we can improve this strategy's performance on the full universe of assets by volatility-normalizing them. For price returns, restricting the universe to the top assets helps the momentum strategy the most. But for funding rate returns, the boost in strategy performance comes from volatility normalizing -- after doing so, it doesn't make much difference whether the universe is restricted to the largest assets.

---

Background info on "funding rates for perpetual futures contracts", per [Coinbase](https://www.coinbase.com/learn/perpetual-futures/understanding-funding-rates-in-perpetual-futures)
- > The funding rate is a fee exchanged periodically between long and short positions in a perpetual futures contract. Unlike traditional futures contracts, perpetual futures don’t have an expiration date, which means they can remain open indefinitely. The funding rate keeps futures prices aligned with the spot price of the underlying asset, helping prevent significant discrepancies over time.
- > Funding rates are generally determined by market demand. When there’s strong demand for long positions, the futures price may rise above the spot price. In this case, the funding rate is positive, meaning traders holding long positions pay traders holding short positions. Conversely, if there’s strong demand for short positions, the futures price may fall below the spot price. Here, the funding rate is negative, and traders holding short positions pay those holding long positions.
- > Funding rates exist to keep the perpetual futures price aligned with the spot price. In traditional futures contracts, convergence to the spot price occurs naturally as the contract approaches its expiration date. Since perpetual futures have no expiration, funding rates serve as a mechanism to balance demand and prevent the futures price from deviating significantly from the spot price. For example, if Bitcoin’s spot price is $30,000 but the futures price is $31,000 due to high demand for long positions, a positive funding rate incentivizes long holders to pay short holders, encouraging a rebalancing of positions. This payment mechanism encourages market participants to open more short positions, bringing the futures price back down closer to the spot price.
